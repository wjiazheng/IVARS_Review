![image](https://github.com/user-attachments/assets/31fa0244-9629-47d8-82fa-be844b902453)![image](https://github.com/user-attachments/assets/32d2eaa1-6b85-46f6-8e79-59804c620932)# Intraoperative Video Analysis in Robotic Surgery: A Literature Review 

Intraoperative video analysis has emerged as a pivotal technology in robot-assisted minimally invasive surgery, enabling real-time interpretation of laparoscopic visual streams to enhance surgical precision, operational safety, and postoperative recovery. 

We categorized intraoperative video analysis in robotic surgery into six core sub-tasks:  
*[Surgical Image Semantic Segmentation](#Surgical_Image_Semantic_Segmentation)*   
Surgical Action Triplet Recognition  
Stereo Matching and 3D Reconstruction in Robotic Surgery  
Preoperative-to-intraoperative Image Registration  
Unsupervised Soft-tissue Tracking  
Surgical Phase Recognition


## Surgical_Image_Semantic_Segmentation  
- Automatic instrument segmentation in robot-assisted surgery using deep learning
- Towards Unsupervised Learning for Instrument Segmentation in Robotic Surgery with Cycle-Consistent Adversarial Networks
- One to Many: Adaptive Instrument Segmentation via Meta Learning and Dynamic Online Adaptation in Robotic Surgical Video
- TraSeTR: Track-to-Segment Transformer with Contrastive Query for Instance-level Instrument Segmentation in Robotic Surgery
- Pseudo-label Guided Cross-video Pixel Contrast for Robotic Surgical Scene Segmentation with Limited Annotations
- MATIS: MASKED-ATTENTION TRANSFORMERS FOR SURGICAL INSTRUMENT SEGMENTATION
- Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference
- Text Promptable Surgical Instrument Segmentation with Vision-Language Models
- Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video
- MSDE-Net: A Multi-Scale Dual-Encoding Network for Surgical Instrument Segmentation
- Structural and Pixel Relation Modeling for Semisupervised Instrument Segmentation From Surgical Videos
- TMF-Net: A Transformer-Based Multiscale Fusion Network for Surgical Instrument Segmentation From Endoscopic Images
- Branch Aggregation Attention Network for Robotic Surgical Instrument Segmentation
- Exploring Intra- and Inter-Video Relation for Surgical Semantic Scene Segmentation
- LSKANet: Long Strip Kernel Attention Network for Robotic Surgical Scene Segmentation
- MSDESIS: Multitask Stereo Disparity Estimation and Surgical Instrument Segmentation
- SSIS-Seg: Simulation-Supervised Image Synthesis for Surgical Instrument Segmentation
- SurgNet: Self-Supervised Pretraining With Semantic Consistency for Vessel and Instrument Segmentation in Surgical Images
- Video-Instrument Synergistic Network for Referring Video Instrument Segmentation in Robotic Surgery
- Surgical-DeSAM: decoupling SAM for instrument segmentation in robotic surgery
- Anchor-guided online meta adaptation for fast one-Shot instrument segmentation from robotic surgical videos
- FUN-SIS: A Fully UNsupervised approach for Surgical Instrument Segmentation
- LACOSTE: Exploiting stereo and temporal contexts for surgical instrument segmentation
- Reducing annotating load: Active learning with synthetic images in surgical instrument
- SurgiNet: Pyramid Attention Aggregation and Class-wise Self-Distillation for Surgical Instrument Segmentation
- Incorporating Temporal Prior from Motion Flow for Instrument Segmentation in Minimally Invasive Surgery Video
- Prototypical Interaction Graph for Unsupervised Domain Adaptation in Surgical Instrument Segmentation
- Co-generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data
- Efficient Global-Local Memory for Real-Time Instrument Segmentation of Robotic Surgical Video
- Rethinking Surgical Instrument Segmentation: A Background Image Can Be All You Need
- Surgical Scene Segmentation Using Semantic Image Synthesis with a Virtual Surgery Environment
- AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation
- SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation
- ISINet: An Instance-Based Approach for Surgical Instrument Segmentation
- Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmen
- Graph-Based Surgical Instrument Adaptive Segmentation via Domain-Common Knowledge
- Endo-Sim2Real: Consistency learning-based domain adaptation for instrument segmentation
- SAM Meets Robotic Surgery: An Empirical Study in Robustness Perspective
- Attention-Guided Lightweight Network for Real-Time Segmentation of Robotic Surgical Instruments
- Pyramid Attention Aggregation Network for Semantic Segmentation of Surgical Instruments
- Space Squeeze Reasoning and Low-Rank Bilinear Feature Fusion for Surgical Image Segmentation

## Surgical_Action_Triplet_Recognition 
- Automatic Gesture Recognition in Robot-assisted Surgery with Reinforcement Learning and Tree Search
- Multi-Task Recurrent Neural Network for Surgical Gesture Recognition and Progress Prediction
- Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery
- Surgical Gesture Recognition Based on Bidirectional Multi-Layer Independently RNN with Explainable Spatial Feature Extraction
- Surgical Triplet Recognition via Diffusion Model
- MT-FiST: A Multi-Task Fine-Grained Spatial-Temporal Framework for Surgical Action Triplet Recognition
- Forest Graph Convolutional Network for Surgical Action Triplet Recognition in Endoscopic Videos
- Gesture Recognition in Robotic Surgery With Multimodal Attention
- Instrument-Tissue Interaction Detection Framework for Surgical Video Understanding
- CholecTriplet2021: A benchmark challenge for surgical action triplet recognition
- Rendezvous: Attention mechanisms for the recognition of surgical action triplets in endoscopic videos
- Using 3D Convolutional Neural Networks to Learn Spatiotemporal Features for Automatic Surgical Gesture Recognition in Video
- Tail-Enhanced Representation Learning for Surgical Triplet Recognition
- Self-distillation for Surgical Action Recognition
- Surgical Action Triplet Detection by Mixed Supervised Learning of Instrument-Tissue Interactions
- Surgical Activity Triplet Recognition via Triplet Disentanglement
- Chain-of-Look Prompting for Verb-centric Surgical Triplet Recognition in Endoscopic Videos
- Concept Graph Neural Networks for  Surgical Video Understanding
- MT4MTL-KD: A Multi-Teacher Knowledge Distillation Framework for Triplet Recognition
- DATA SPLITS AND METRICS FOR METHOD BENCHMARKING ON SURGICAL ACTION TRIPLET DATASETS
- Parameter-efÔ¨Åcient framework for surgical action triplet recognition

## Stereo_Matching_and_3D_Reconstruction_in_Robotic_Surgery
- A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics
- REAL-TIME COARSE-TO-FINE DEPTH ESTIMATION ON STEREO ENDOSCOPIC IMAGES WITH SELF-SUPERVISED LEARNING
- Self-Supervised Learning for Monocular Depth Estimation on Minimally Invasive Surgery Scenes
- Unsupervised-Learning-Based Continuous Depth and Motion Estimation With Monocular Endoscopy for Virtual Reality Minimally Invasive Surgery
- EndoMODE: A Multimodal Visual Feature-Based Ego-Motion Estimation Framework for Monocular Odometry and Depth Estimation in Various Endoscopic Scenes
- Real-Time Dense Reconstruction of Tissue Surface From Stereo Optical Video
- Bidirectional Semi-Supervised Dual-Branch CNN for Robust 3D Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel Supervisions.
- A Robust Edge-Preserving Stereo Matching Method for Laparoscopic Images
- Self-Supervised Monocular Depth Estimation With 3-D Displacement Module for Laparoscopic Images
- Simultaneous Depth Estimation and Surgical Tool Segmentation in Laparoscopic Images
- SVT-SDE: Spatiotemporal Vision Transformers-Based Self-Supervised Depth Estimation in Stereoscopic Surgical Videos
- A Self-Supervised Network-Based Smoke Removal and Depth Estimation for Monocular Endoscopic Videos
- Surgical Suture Thread Detection and 3-D Reconstruction Using a Model-Free Approach in a Calibrated Stereo Visual System
- WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation on Surgical Videos with Unknown Camera Parameters
- Surgical-DINO: adapter learning of foundation models for depth estimation in endoscopic surgery
- Enhanced self-supervised monocular depth estimation with self-attention and joint depth-pose loss for laparoscopic images
- Stereo matching of binocular laparoscopic images with improved densely connected neural architecture search
- The RoDEM benchmark: evaluating the robustness of monocular single-shot depth estimation methods in minimally-invasive surgery
- EndoAbS dataset: Endoscopic abdominal stereo image dataset for benchmarking 3D stereo reconstruction algorithms
- Disparity refinement framework for learning-based stereo matching methods in cross-domain setting for laparoscopic images
- WS-SfMLearner: self-supervised monocular depth and ego-motion estimation on surgical videos with unknown camera parameters.
- EndoSLAM dataset and an unsupervised monocular visual odometry and depth estimation approach for endoscopic videos
- MonoPCC: Photometric-invariant cycle constraint for monocular depth estimation of endoscopic images
- Simultaneous Surgical Visibility Assessment, Restoration, and Augmented Stereo Surface Reconstruction for Robotic Prostatectomy
- EMDQ-SLAM: Real-Time High-Resolution Reconstruction of Soft Tissue Surface from Stereo Laparoscopy Videos
- Self-supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images
- EndoDAC: Efficient Adapting Foundation Model for Self-Supervised Depth Estimation from Any Endoscopic Camera
- Enhanced Scale-Aware Depth Estimation for Monocular Endoscopic Scenes with Geometric Modeling
- Geometric Constraints for Self-supervised Monocular Depth Estimation on Laparoscopic Images with Dual-task Consistency
- Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery
- Self-supervised Depth Estimation in Laparoscopic Image Using 3D Geometric Consistency
- Bayesian Dense Inverse Searching Algorithm for Real-Time Stereo Matching in Minimally Invasive Surgery
- Deep Laparoscopic Stereo Matching with Transformers
- EndoSurf: Neural Surface Reconstruction of Deformable Tissues with Stereo Endoscope Videos
- Multi-view Guidance for Self-supervised Monocular Depth Estimation on Laparoscopic Images via Spatio-Temporal Correspondence
- Context Encoder Guided Self-Supervised Siamese Depth Estimation Based on Stereo Laparoscopic Images
- Self-supervised Depth Estimation with Uncertainty-weight Joint Loss Function Based on Laparoscopic Videos
- Automatic 3D Point Set Reconstruction from Stereo Laparoscopic Images using Deep Neural Networks
- The Effect of Luminance on Depth Perception in Augmented Reality Guided Laparoscopic Surgery.
- A Disparity Refinement Framework for Learning-based Stereo Matching Methods in Cross-domain Setting for Laparoscopic Images.
- Semi-supervised Learning via Improved Teacher-Student Network for Robust 3D Reconstruction of Stereo Endoscopic Image
- Confidence-aware self-supervised learning for dense monocular depth estimation in dynamic laparoscopic scene
- A monocular endoscopic image depth estimation method based on a window-adaptive asymmetric dual-branch Siamese network.
- Robust Cost Volume Generation Method for Dense Stereo Matching in Endoscopic Scenarios
- Benchmarking Robustness of Endoscopic Depth Estimation with Synthetically Corrupted Data
- Revisiting Stereo Depth Estimation From a Sequence-to-Sequence Perspective with Transformers
- MSDESIS: Multitask Stereo Disparity Estimation and Surgical Instrument Segmentation
- E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with Transformer-based Stereoscopic Depth Perception
- BDIS-SLAM: A lightweight CPU-based dense stereo SLAM for surgery
- Robust endoscopic image mosaicking via fusion of multimodal estimation
- Neural LerPlane Representations for Fast 4D Reconstruction of Deformable Tissues
- EndoGaussian: Real-time Gaussian Splatting for ynamic Endoscopic Scene Reconstruction
- StaSiS-Net: A stacked and siamese disparity estimation network for depth reconstruction in modern 3D laparoscopy















